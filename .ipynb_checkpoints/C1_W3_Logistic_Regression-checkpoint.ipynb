{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regress√£o Log√≠stica\n",
    "\n",
    "Neste exerc√≠cio, voc√™ implementar√° a regress√£o log√≠stica e aplicar√° a dois conjuntos de dados diferentes.\n",
    "\n",
    "# Resumo\n",
    "- [1 - Pacotes](#1)\n",
    "- [2 - Regress√£o Log√≠stica](#2)\n",
    "  - [2.1 Enunciado do Problema](#2.1)\n",
    "  - [2.2 Carregando e visualizando os dados](#2.2)\n",
    "  - [2.3 Fun√ß√£o Sigmoide](#2.3)\n",
    "  - [2.4 Fun√ß√£o de custo para regress√£o log√≠stica](#2.4)\n",
    "  - [2.5 Gradiente para regress√£o log√≠stica](#2.5)\n",
    "  - [2.6 Aprendendo par√¢metros usando descida de gradiente](#2.6)\n",
    "  - [2.7 Plotando a fronteira de decis√£o](#2.7)\n",
    "  - [2.8 Avaliando a regress√£o log√≠stica](#2.8)\n",
    "- [3 - Regress√£o Log√≠stica Regularizada](#3)\n",
    "  - [3.1 Enunciado do Problema](#3.1)\n",
    "  - [3.2 Carregando e visualizando os dados](#3.2)\n",
    "  - [3.3 Mapeamento de caracter√≠sticas](#3.3)\n",
    "  - [3.4 Fun√ß√£o de custo para regress√£o log√≠stica regularizada](#3.4)\n",
    "  - [3.5 Gradiente para regress√£o log√≠stica regularizada](#3.5)\n",
    "  - [3.6 Aprendendo par√¢metros usando descida de gradiente](#3.6)\n",
    "  - [3.7 Plotando a fronteira de decis√£o](#3.7)\n",
    "  - [3.8 Avaliando o modelo de regress√£o log√≠stica regularizada](#3.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**NOTA:** Para evitar erros no autograder, voc√™ n√£o pode editar ou deletar c√©lulas n√£o avaliadas neste laborat√≥rio. Por favor, tamb√©m evite adicionar novas c√©lulas. **Uma vez que voc√™ tenha passado nesta tarefa** e quiser experimentar qualquer um dos c√≥digos n√£o avaliados, voc√™ pode seguir as instru√ß√µes no final deste notebook._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "## 1 - Pacotes\n",
    "\n",
    "Primeiro, vamos executar a c√©lula abaixo para importar todos os pacotes que voc√™ precisar√° durante esta tarefa.\n",
    "- [numpy](www.numpy.org) √© o pacote fundamental para computa√ß√£o cient√≠fica com Python.\n",
    "- [matplotlib](http://matplotlib.org) √© uma biblioteca famosa para plotar gr√°ficos em Python.\n",
    "- `utils.py` cont√©m fun√ß√µes auxiliares para esta tarefa. Voc√™ n√£o precisa modificar o c√≥digo neste arquivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "import copy\n",
    "import math\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "## 2 - Regress√£o Log√≠stica\n",
    "\n",
    "Nesta parte do exerc√≠cio, voc√™ construir√° um modelo de regress√£o log√≠stica para prever se um estudante ser√° admitido em uma universidade.\n",
    "\n",
    "<a name=\"2.1\"></a>\n",
    "### 2.1 Enunciado do Problema\n",
    "\n",
    "Suponha que voc√™ √© o administrador de um departamento universit√°rio e deseja determinar a chance de admiss√£o de cada candidato com base nos resultados de dois exames.\n",
    "* Voc√™ tem dados hist√≥ricos de candidatos anteriores que podem ser usados como um conjunto de treinamento para regress√£o log√≠stica.\n",
    "* Para cada exemplo de treinamento, voc√™ tem as notas dos candidatos em dois exames e a decis√£o de admiss√£o.\n",
    "* Sua tarefa √© construir um modelo de classifica√ß√£o que estime a probabilidade de admiss√£o de um candidato com base nas notas desses dois exames.\n",
    "\n",
    "<a name=\"2.2\"></a>\n",
    "### 2.2 Carregando e visualizando os dados\n",
    "\n",
    "Voc√™ come√ßar√° carregando o conjunto de dados para esta tarefa.\n",
    "- A fun√ß√£o `load_dataset()` mostrada abaixo carrega os dados em vari√°veis `X_train` e `y_train`.\n",
    "  - `X_train` cont√©m as notas dos exames de dois exames para um estudante.\n",
    "  - `y_train` √© a decis√£o de admiss√£o.\n",
    "    - `y_train = 1` se o estudante foi admitido.\n",
    "    - `y_train = 0` se o estudante n√£o foi admitido.\n",
    "  - Tanto `X_train` quanto `y_train` s√£o arrays do numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# carregar o conjunto de dados\n",
    "X_train, y_train = load_data(\"data/ex2data1.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizar as vari√°veis\n",
    "Vamos nos familiarizar mais com seu conjunto de dados.  \n",
    "- Um bom lugar para come√ßar √© simplesmente imprimir cada vari√°vel e ver o que ela cont√©m.\n",
    "\n",
    "O c√≥digo abaixo imprime os primeiros cinco valores de `X_train` e o tipo da vari√°vel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os cinco primeiros elementos em X_train s√£o:\n",
      " [[34.62365962 78.02469282]\n",
      " [30.28671077 43.89499752]\n",
      " [35.84740877 72.90219803]\n",
      " [60.18259939 86.3085521 ]\n",
      " [79.03273605 75.34437644]]\n",
      "Tipo de X_train: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Os cinco primeiros elementos em X_train s√£o:\\n\", X_train[:5])\n",
    "print(\"Tipo de X_train:\", type(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora imprima os primeiros cinco valores de `y_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os cinco primeiros elementos em y_train s√£o:\n",
      " [0. 0. 0. 1. 1.]\n",
      "Tipo de y_train: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Os cinco primeiros elementos em y_train s√£o:\\n\", y_train[:5])\n",
    "print(\"Tipo de y_train:\", type(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verifique as dimens√µes das suas vari√°veis\n",
    "\n",
    "Outra maneira √∫til de se familiarizar com seus dados √© visualizar suas dimens√µes. Vamos imprimir a forma de `X_train` e `y_train` e ver quantos exemplos de treinamento temos em nosso conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A forma de X_train √©: (100, 2)\n",
      "A forma de y_train √©: (100,)\n",
      "Temos m = 100 exemplos de treinamento\n"
     ]
    }
   ],
   "source": [
    "print('A forma de X_train √©: ' + str(X_train.shape))\n",
    "print('A forma de y_train √©: ' + str(y_train.shape))\n",
    "print('Temos m = %d exemplos de treinamento' % (len(y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizar os dados\n",
    "\n",
    "Antes de come√ßar a implementar qualquer algoritmo de aprendizado, √© sempre bom visualizar os dados, se poss√≠vel.\n",
    "- O c√≥digo abaixo exibe os dados em um gr√°fico 2D (como mostrado abaixo), onde os eixos s√£o as notas dos dois exames, e os exemplos positivos e negativos s√£o mostrados com marcadores diferentes.\n",
    "- Usamos uma fun√ß√£o auxiliar no arquivo `utils.py` para gerar este gr√°fico.\n",
    "\n",
    "<img src=\"images/figure 1.png\" width=\"450\" height=\"450\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotar exemplos\n",
    "plot_data(X_train, y_train[:], pos_label=\"Admitido\", neg_label=\"N√£o admitido\")\n",
    "\n",
    "# Definir o r√≥tulo do eixo y\n",
    "plt.ylabel('Nota do Exame 2')\n",
    "# Definir o r√≥tulo do eixo x\n",
    "plt.xlabel('Nota do Exame 1')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seu objetivo √© construir um modelo de regress√£o log√≠stica para ajustar esses dados.\n",
    "- Com este modelo, voc√™ pode prever se um novo estudante ser√° admitido com base nas notas dos dois exames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2.3\"></a>\n",
    "### 2.3 Fun√ß√£o Sigmoide\n",
    "\n",
    "Lembre-se de que para a regress√£o log√≠stica, o modelo √© representado como\n",
    "\n",
    "$$ f_{\\mathbf{w},b}(x) = g(\\mathbf{w}\\cdot \\mathbf{x} + b)$$\n",
    "\n",
    "onde a fun√ß√£o $g$ √© a fun√ß√£o sigmoide. A fun√ß√£o sigmoide √© definida como:\n",
    "\n",
    "$$g(z) = \\frac{1}{1+e^{-z}}$$\n",
    "\n",
    "Vamos implementar a fun√ß√£o sigmoide primeiro, para que ela possa ser usada no restante desta tarefa.\n",
    "\n",
    "<a name='ex-01'></a>\n",
    "### Exerc√≠cio 1\n",
    "Por favor, complete a fun√ß√£o `sigmoid` para calcular\n",
    "\n",
    "$$g(z) = \\frac{1}{1+e^{-z}}$$\n",
    "\n",
    "Note que \n",
    "- `z` nem sempre √© um √∫nico n√∫mero, mas tamb√©m pode ser um array de n√∫meros.\n",
    "- Se a entrada for um array de n√∫meros, gostar√≠amos de aplicar a fun√ß√£o sigmoide a cada valor no array de entrada.\n",
    "\n",
    "Se voc√™ ficar preso, pode consultar as dicas apresentadas ap√≥s a c√©lula abaixo para ajudar na implementa√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C1\n",
    "# GRADED FUNCTION: sigmoid\n",
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Calcula a fun√ß√£o sigmoide de z\n",
    "\n",
    "    Args:\n",
    "        z (ndarray): Um escalar, array numpy de qualquer tamanho.\n",
    "\n",
    "    Returns:\n",
    "        g (ndarray): sigmoid(z), com a mesma forma de z\n",
    "         \n",
    "    \"\"\"\n",
    "      \n",
    "    ### IN√çCIO DO C√ìDIGO ###\n",
    "    g = 1 / (1 + np.exp(-z))\n",
    "    ### FIM DO C√ìDIGO ###  \n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><font size=\"3\" color=\"darkgreen\"><b>Clique para dicas</b></font></summary>\n",
    "       \n",
    "   * `numpy` tem uma fun√ß√£o chamada [`np.exp()`](https://numpy.org/doc/stable/reference/generated/numpy.exp.html), que oferece uma maneira conveniente de calcular o exponencial ( $e^{z}$) de todos os elementos no array de entrada (`z`).\n",
    "\n",
    "<details>\n",
    "          <summary><font size=\"2\" color=\"darkblue\"><b>Clique para mais dicas</b></font></summary>\n",
    "        \n",
    "  - Voc√™ pode traduzir $e^{-z}$ para c√≥digo como `np.exp(-z)`.\n",
    "    \n",
    "  - Voc√™ pode traduzir $1/e^{-z}$ para c√≥digo como `1/np.exp(-z)`.\n",
    "    \n",
    "    Se voc√™ ainda estiver preso, pode consultar as dicas apresentadas abaixo para descobrir como calcular `g`.\n",
    "\n",
    "    <details>\n",
    "          <summary><font size=\"2\" color=\"darkblue\"><b>Dica para calcular g</b></font></summary>\n",
    "        <code>g = 1 / (1 + np.exp(-z))</code>\n",
    "    </details>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando terminar, tente testar alguns valores chamando `sigmoid(x)` na c√©lula abaixo.\n",
    "- Para grandes valores positivos de x, a sigmoide deve ser pr√≥xima de 1, enquanto para grandes valores negativos, a sigmoide deve ser pr√≥xima de 0.\n",
    "- Avaliar `sigmoid(0)` deve dar exatamente 0,5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid(0) = 0.5\n"
     ]
    }
   ],
   "source": [
    "# Nota: Voc√™ pode editar este valor\n",
    "value = 0\n",
    "\n",
    "print(f\"sigmoid({value}) = {sigmoid(value)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sa√≠da Esperada**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>sigmoid(0)<b></td>\n",
    "    <td> 0.5 </td> \n",
    "  </tr>\n",
    "</table>\n",
    "    \n",
    "- Como mencionado antes, seu c√≥digo tamb√©m deve funcionar com vetores e matrizes. Para uma matriz, sua fun√ß√£o deve realizar a fun√ß√£o sigmoide em cada elemento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid([ -1, 0, 1, 2]) = [0.26894142 0.5        0.73105858 0.88079708]\n",
      "\u001b[92mAll tests passed!\n"
     ]
    }
   ],
   "source": [
    "print (\"sigmoid([ -1, 0, 1, 2]) = \" + str(sigmoid(np.array([-1, 0, 1, 2]))))\n",
    "\n",
    "# UNIT TESTS\n",
    "from public_tests import *\n",
    "sigmoid_test(sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sa√≠da Esperada**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>sigmoid([ -1,  0,  1,  2])<b></td>\n",
    "    <td> [0.26894142 0.5        0.73105858 0.88079708] </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2.4\"></a>\n",
    "### 2.4 Fun√ß√£o de Custo para Regress√£o Log√≠stica\n",
    "\n",
    "Nesta se√ß√£o, voc√™ implementar√° a fun√ß√£o de custo para regress√£o log√≠stica.\n",
    "\n",
    "<a name='ex-02'></a>\n",
    "### Exerc√≠cio 2\n",
    "\n",
    "Por favor, complete a fun√ß√£o `compute_cost` usando as equa√ß√µes abaixo.\n",
    "\n",
    "Lembre-se de que para a regress√£o log√≠stica, a fun√ß√£o de custo √© da forma\n",
    "\n",
    "$$ J(\\mathbf{w},b) = \\frac{1}{m}\\sum_{i=0}^{m-1} \\left[ loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)}) \\right] \\tag{1}$$\n",
    "\n",
    "onde\n",
    "* m √© o n√∫mero de exemplos de treinamento no conjunto de dados\n",
    "\n",
    "* $loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)})$ √© o custo para um √∫nico ponto de dados, que √©\n",
    "\n",
    "    $$loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)}) = (-y^{(i)} \\log\\left(f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) - \\left( 1 - y^{(i)}\\right) \\log \\left( 1 - f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) \\tag{2}$$\n",
    "    \n",
    "*  $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)})$ √© a previs√£o do modelo, enquanto $y^{(i)}$ √© o r√≥tulo real\n",
    "\n",
    "*  $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = g(\\mathbf{w} \\cdot \\mathbf{x^{(i)}} + b)$ onde a fun√ß√£o $g$ √© a fun√ß√£o sigmoide.\n",
    "    * Pode ser √∫til primeiro calcular uma vari√°vel intermedi√°ria $z_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = \\mathbf{w} \\cdot \\mathbf{x^{(i)}} + b = w_0x^{(i)}_0 + ... + w_{n-1}x^{(i)}_{n-1} + b$ onde $n$ √© o n√∫mero de caracter√≠sticas, antes de calcular $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = g(z_{\\mathbf{w},b}(\\mathbf{x}^{(i)}))$\n",
    "\n",
    "Nota:\n",
    "* Enquanto voc√™ faz isso, lembre-se de que as vari√°veis `X_train` e `y_train` n√£o s√£o valores escalares, mas matrizes de forma ($m, n$) e ($ùëö$,1) respectivamente, onde $ùëõ$ √© o n√∫mero de caracter√≠sticas e $ùëö$ √© o n√∫mero de exemplos de treinamento.\n",
    "* Voc√™ pode usar a fun√ß√£o sigmoide que voc√™ implementou acima para esta parte.\n",
    "\n",
    "Se voc√™ ficar preso, pode conferir as dicas apresentadas ap√≥s a c√©lula abaixo para ajudar na implementa√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C2\n",
    "# GRADED FUNCTION: compute_cost\n",
    "def compute_cost(X, y, w, b, *argv):\n",
    "    \"\"\"\n",
    "    Calcula o custo sobre todos os exemplos\n",
    "    Args:\n",
    "      X : (ndarray Shape (m,n)) dados, m exemplos por n caracter√≠sticas\n",
    "      y : (ndarray Shape (m,))  valor alvo \n",
    "      w : (ndarray Shape (n,))  valores dos par√¢metros do modelo      \n",
    "      b : (escalar)              valor do par√¢metro de vi√©s do modelo\n",
    "      *argv : n√£o utilizado, para compatibilidade com a vers√£o regularizada abaixo\n",
    "    Returns:\n",
    "      total_cost : (escalar) custo \n",
    "    \"\"\"\n",
    "\n",
    "    m, n = X.shape\n",
    "    \n",
    "    ### IN√çCIO DO C√ìDIGO ###\n",
    "    loss_sum = 0\n",
    "    # Loop sobre cada exemplo de treinamento\n",
    "    for i in range(m): \n",
    "\n",
    "        # Primeiro calcule z_wb = w[0]*X[i][0]+...+w[n-1]*X[i][n-1]+b\n",
    "        z_wb = 0 \n",
    "        # Loop sobre cada caracter√≠stica\n",
    "        for j in range(n): \n",
    "            # Adicione o termo correspondente a z_wb\n",
    "            z_wb_ij = w[j] * X[i][j]\n",
    "            z_wb += z_wb_ij # equivalente a z_wb = z_wb + z_wb_ij\n",
    "        # Adicione o termo de vi√©s a z_wb\n",
    "        z_wb += b # equivalente a z_wb = z_wb + b\n",
    "\n",
    "        f_wb = sigmoid(z_wb)\n",
    "        loss =  -y[i] * np.log(f_wb) - (1 - y[i]) * np.log(1 - f_wb)\n",
    "\n",
    "        loss_sum += loss # equivalente a loss_sum = loss_sum + loss\n",
    "\n",
    "    total_cost = (1 / m) * loss_sum  \n",
    "    ### FIM DO C√ìDIGO ### \n",
    "\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><font size=\"3\" color=\"darkgreen\"><b>Clique para dicas</b></font></summary>\n",
    "    \n",
    "* Voc√™ pode representar um operador de soma, por exemplo: $h = \\sum\\limits_{i = 0}^{m-1} 2i$ em c√≥digo da seguinte forma:\n",
    "\n",
    "```python\n",
    "    h = 0\n",
    "    for i in range(m):\n",
    "        h = h + 2*i\n",
    "```\n",
    "<br>\n",
    "\n",
    "* Neste caso, voc√™ pode iterar sobre todos os exemplos em `X` usando um loop `for` e adicionar o `loss` de cada itera√ß√£o a uma vari√°vel (`loss_sum`) inicializada fora do loop.\n",
    "\n",
    "* Em seguida, voc√™ pode retornar o `total_cost` como `loss_sum` dividido por `m`.\n",
    "\n",
    "* Se voc√™ √© novo em Python, verifique se o seu c√≥digo est√° devidamente indentado com espa√ßos ou abas consistentes. Caso contr√°rio, pode gerar uma sa√≠da diferente ou levantar um erro `IndentationError: unexpected indent`. Voc√™ pode consultar [este t√≥pico](https://community.deeplearning.ai/t/indentation-in-python-indentationerror-unexpected-indent/159398) em nossa comunidade para mais detalhes.\n",
    "     \n",
    "<details>\n",
    "<summary><font size=\"2\" color=\"darkblue\"><b>Clique para mais dicas</b></font></summary>\n",
    "        \n",
    "* Aqui est√° como voc√™ pode estruturar a implementa√ß√£o geral para esta fun√ß√£o\n",
    "        \n",
    "```python\n",
    "def compute_cost(X, y, w, b, *argv):\n",
    "    m, n = X.shape\n",
    "\n",
    "    ### IN√çCIO DO C√ìDIGO ###\n",
    "    loss_sum = 0 \n",
    "    \n",
    "    # Loop sobre cada exemplo de treinamento\n",
    "    for i in range(m): \n",
    "        \n",
    "        # Primeiro calcule z_wb = w[0]*X[i][0]+...+w[n-1]*X[i][n-1]+b\n",
    "        z_wb = 0 \n",
    "        # Loop sobre cada caracter√≠stica\n",
    "        for j in range(n): \n",
    "            # Adicione o termo correspondente a z_wb\n",
    "            z_wb_ij = # Seu c√≥digo aqui para calcular w[j] * X[i][j]\n",
    "            z_wb += z_wb_ij # equivalente a z_wb = z_wb + z_wb_ij\n",
    "        # Adicione o termo de vi√©s a z_wb\n",
    "        z_wb += b # equivalente a z_wb = z_wb + b\n",
    "        \n",
    "        f_wb = # Seu c√≥digo aqui para calcular a previs√£o f_wb para um exemplo de treinamento\n",
    "        loss =  # Seu c√≥digo aqui para calcular o loss para um exemplo de treinamento\n",
    "        \n",
    "        loss_sum += loss # equivalente a loss_sum = loss_sum + loss\n",
    "        \n",
    "    total_cost = (1 / m) * loss_sum  \n",
    "    ### FIM DO C√ìDIGO ### \n",
    "    \n",
    "    return total_cost\n",
    "```\n",
    "<br>\n",
    "\n",
    "Se voc√™ ainda estiver preso, pode verificar as dicas apresentadas abaixo para descobrir como calcular `z_wb_ij`, `f_wb` e `cost`.\n",
    "\n",
    "<details>\n",
    "<summary><font size=\"2\" color=\"darkblue\"><b>Dica para calcular z_wb_ij</b></font></summary>\n",
    "           &emsp; &emsp; <code>z_wb_ij = w[j]*X[i][j] </code>\n",
    "</details>\n",
    "        \n",
    "<details>\n",
    "          <summary><font size=\"2\" color=\"darkblue\"><b>Dica para calcular f_wb</b></font></summary>\n",
    "           &emsp; &emsp; $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = g(z_{\\mathbf{w},b}(\\mathbf{x}^{(i)}))$ onde $g$ √© a fun√ß√£o sigmoide. Voc√™ pode simplesmente chamar a fun√ß√£o `sigmoid` implementada acima.\n",
    "          <details>\n",
    "              <summary><font size=\"2\" color=\"blue\"><b>&emsp; &emsp; Mais dicas para calcular f</b></font></summary>\n",
    "               &emsp; &emsp; Voc√™ pode calcular f_wb como <code>f_wb = sigmoid(z_wb) </code>\n",
    "           </details>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "          <summary><font size=\"2\" color=\"darkblue\"><b>Dica para calcular o loss</b></font></summary>\n",
    "          &emsp; &emsp; Voc√™ pode usar a fun√ß√£o <a href=\"https://numpy.org/doc/stable/reference/generated/numpy.log.html\">np.log</a> para calcular o logaritmo\n",
    "          <details>\n",
    "              <summary><font size=\"2\" color=\"blue\"><b>&emsp; &emsp; Mais dicas para calcular o loss</b></font></summary>\n",
    "              &emsp; &emsp; Voc√™ pode calcular o loss como <code>loss =  -y[i] * np.log(f_wb) - (1 - y[i]) * np.log(1 - f_wb)</code>\n",
    "</details>\n",
    "</details>\n",
    "        \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute as c√©lulas abaixo para verificar a sua implementa√ß√£o da fun√ß√£o `compute_cost` com duas inicializa√ß√µes diferentes dos par√¢metros $w$ e $b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custo com w e b iniciais (zeros): 0.693\n"
     ]
    }
   ],
   "source": [
    "m, n = X_train.shape\n",
    "\n",
    "# Calcular e exibir o custo com w e b inicializados a zeros\n",
    "initial_w = np.zeros(n)\n",
    "initial_b = 0.\n",
    "cost = compute_cost(X_train, y_train, initial_w, initial_b)\n",
    "print('Custo com w e b iniciais (zeros): {:.3f}'.format(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sa√≠da Esperada**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>Custo com w e b iniciais (zeros)<b></td>\n",
    "    <td> 0,693 </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custo com w e b de teste (diferentes de zero): 0.218\n",
      "\u001b[92mAll tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Calcular e exibir o custo com w e b diferentes de zero\n",
    "test_w = np.array([0.2, 0.2])\n",
    "test_b = -24.\n",
    "cost = compute_cost(X_train, y_train, test_w, test_b)\n",
    "\n",
    "print('Custo com w e b de teste (diferentes de zero): {:.3f}'.format(cost))\n",
    "\n",
    "\n",
    "# UNIT TESTS\n",
    "compute_cost_test(compute_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sa√≠da Esperada**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>Custo com w e b de teste (diferentes de zero):<b></td>\n",
    "    <td> 0,218 </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2.5\"></a>\n",
    "### 2.5 Gradiente para regress√£o log√≠stica\n",
    "\n",
    "Nesta se√ß√£o, voc√™ implementar√° o gradiente para regress√£o log√≠stica.\n",
    "\n",
    "Lembre-se de que o algoritmo de descida de gradiente √©:\n",
    "\n",
    "$$\\begin{align*}& \\text{repetir at√© converg√™ncia:} \\; \\lbrace \\newline \\; & b := b -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial b} \\newline       \\; & w_j := w_j -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j} \\tag{1}  \\; & \\text{para j := 0..n-1}\\newline & \\rbrace\\end{align*}$$\n",
    "\n",
    "onde, os par√¢metros $b$, $w_j$ s√£o todos atualizados simultaneamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-03'></a>\n",
    "### Exerc√≠cio 3\n",
    "\n",
    "Por favor, complete a fun√ß√£o `compute_gradient` para calcular $\\frac{\\partial J(\\mathbf{w},b)}{\\partial w}$, $\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}$ a partir das equa√ß√µes (2) e (3) abaixo.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  = \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - \\mathbf{y}^{(i)}) \\tag{2}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  = \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - \\mathbf{y}^{(i)})x_{j}^{(i)} \\tag{3}\n",
    "$$\n",
    "* m √© o n√∫mero de exemplos de treinamento no conjunto de dados\n",
    "\n",
    "    \n",
    "*  $f_{\\mathbf{w},b}(x^{(i)})$ √© a previs√£o do modelo, enquanto $y^{(i)}$ √© o r√≥tulo real\n",
    "\n",
    "\n",
    "- **Nota**: Embora este gradiente pare√ßa id√™ntico ao gradiente da regress√£o linear, a f√≥rmula √© realmente diferente porque a regress√£o linear e a regress√£o log√≠stica t√™m defini√ß√µes diferentes de $f_{\\mathbf{w},b}(x)$.\n",
    "\n",
    "Como antes, voc√™ pode usar a fun√ß√£o sigmoide que implementou acima e, se ficar preso, pode conferir as dicas apresentadas ap√≥s a c√©lula abaixo para ajud√°-lo com a implementa√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C3\n",
    "# GRADED FUNCTION: compute_gradient\n",
    "def compute_gradient(X, y, w, b, *argv): \n",
    "    \"\"\"\n",
    "    Calcula o gradiente para regress√£o log√≠stica\n",
    " \n",
    "    Args:\n",
    "      X : (ndarray Shape (m,n)) dados, m exemplos por n caracter√≠sticas\n",
    "      y : (ndarray Shape (m,))  valor alvo \n",
    "      w : (ndarray Shape (n,))  valores dos par√¢metros do modelo      \n",
    "      b : (escalar)              valor do par√¢metro de vi√©s do modelo\n",
    "      *argv : n√£o utilizado, para compatibilidade com a vers√£o regularizada abaixo\n",
    "    Returns\n",
    "      dj_dw : (ndarray Shape (n,)) O gradiente do custo em rela√ß√£o aos par√¢metros w. \n",
    "      dj_db : (escalar)             O gradiente do custo em rela√ß√£o ao par√¢metro b. \n",
    "    \"\"\"\n",
    "    m, n = X.shape\n",
    "    dj_dw = np.zeros(w.shape)\n",
    "    dj_db = 0.\n",
    "\n",
    "    ### IN√çCIO DO C√ìDIGO AQUI ### \n",
    "    for i in range(m):\n",
    "        # Calcular f_wb (exatamente como voc√™ fez na fun√ß√£o compute_cost acima)\n",
    "        z_wb = 0\n",
    "        # Iterar sobre cada caracter√≠stica\n",
    "        for j in range(n): \n",
    "            # Adicionar o termo correspondente a z_wb\n",
    "            z_wb_ij = X[i, j] * w[j]\n",
    "            z_wb += z_wb_ij\n",
    "            \n",
    "        # Adicionar o termo de vi√©s \n",
    "        z_wb += b\n",
    "        \n",
    "        # Calcular a previs√£o do modelo\n",
    "        f_wb = sigmoid(z_wb)\n",
    "        \n",
    "        # Calcular o gradiente para b deste exemplo\n",
    "        dj_db_i = f_wb - y[i]\n",
    "        \n",
    "        # adicionar isso a dj_db\n",
    "        dj_db += dj_db_i\n",
    "        \n",
    "        # obter dj_dw para cada atributo\n",
    "        for j in range(n):\n",
    "            # Seu c√≥digo aqui para calcular o gradiente do exemplo i para o atributo j\n",
    "            dj_dw_ij = (f_wb - y[i])* X[i][j]\n",
    "            dj_dw[j] += dj_dw_ij\n",
    "        \n",
    "    # dividir dj_db e dj_dw pelo n√∫mero total de exemplos\n",
    "    dj_dw = dj_dw / m\n",
    "    dj_db = dj_db / m\n",
    "    ### FIM DO C√ìDIGO AQUI ###\n",
    "       \n",
    "    return dj_db, dj_dw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><font size=\"3\" color=\"darkgreen\"><b>Clique para dicas</b></font></summary>\n",
    "    \n",
    "    \n",
    "* Aqui est√° como voc√™ pode estruturar a implementa√ß√£o geral desta fun√ß√£o\n",
    "    ```python \n",
    "       def compute_gradient(X, y, w, b, *argv): \n",
    "            m, n = X.shape\n",
    "            dj_dw = np.zeros(w.shape)\n",
    "            dj_db = 0.\n",
    "        \n",
    "            ### IN√çCIO DO C√ìDIGO AQUI ### \n",
    "            for i in range(m):\n",
    "                # Calcular f_wb (exatamente como voc√™ fez na fun√ß√£o compute_cost acima)\n",
    "                f_wb = \n",
    "        \n",
    "                # Calcular o gradiente para b deste exemplo\n",
    "                dj_db_i = # Seu c√≥digo aqui para calcular o erro\n",
    "        \n",
    "                # adicionar isso a dj_db\n",
    "                dj_db += dj_db_i\n",
    "        \n",
    "                # obter dj_dw para cada atributo\n",
    "                for j in range(n):\n",
    "                    # Seu c√≥digo aqui para calcular o gradiente do exemplo i para o atributo j\n",
    "                    dj_dw_ij =  \n",
    "                    dj_dw[j] += dj_dw_ij\n",
    "        \n",
    "            # dividir dj_db e dj_dw pelo n√∫mero total de exemplos\n",
    "            dj_dw = dj_dw / m\n",
    "            dj_db = dj_db / m\n",
    "            ### FIM DO C√ìDIGO AQUI ###\n",
    "       \n",
    "            return dj_db, dj_dw\n",
    "    ```\n",
    "\n",
    "    * Se voc√™ √© novo em Python, verifique se seu c√≥digo est√° devidamente indentado com espa√ßos ou tabula√ß√µes consistentes. Caso contr√°rio, pode produzir uma sa√≠da diferente ou gerar um erro de `IndentationError: unexpected indent`. Voc√™ pode consultar [este t√≥pico](https://community.deeplearning.ai/t/indentation-in-python-indentationerror-unexpected-indent/159398) em nossa comunidade para mais detalhes.\n",
    "    * Se ainda estiver com dificuldades, voc√™ pode verificar as dicas apresentadas abaixo para descobrir como calcular `f_wb`, `dj_db_i` e `dj_dw_ij` \n",
    "    \n",
    "    <details>\n",
    "          <summary><font size=\"2\" color=\"darkblue\"><b>Dica para calcular f_wb</b></font></summary>\n",
    "           &emsp; &emsp; Lembre-se de que voc√™ calculou f_wb na fun√ß√£o <code>compute_cost</code> acima ‚Äî para dicas detalhadas sobre como calcular cada termo intermedi√°rio, consulte a se√ß√£o de dicas abaixo daquele exerc√≠cio\n",
    "           <details>\n",
    "              <summary><font size=\"2\" color=\"blue\"><b>&emsp; &emsp; Mais dicas para calcular f_wb</b></font></summary>\n",
    "              &emsp; &emsp; Voc√™ pode calcular f_wb como\n",
    "               <pre>\n",
    "               for i in range(m):   \n",
    "                   # Calcular f_wb (exatamente como voc√™ fez na fun√ß√£o compute_cost acima)\n",
    "                   z_wb = 0\n",
    "                   # Iterar sobre cada caracter√≠stica\n",
    "                   for j in range(n): \n",
    "                       # Adicionar o termo correspondente a z_wb\n",
    "                       z_wb_ij = X[i, j] * w[j]\n",
    "                       z_wb += z_wb_ij\n",
    "            \n",
    "                   # Adicionar o termo de vi√©s \n",
    "                   z_wb += b\n",
    "        \n",
    "                   # Calcular a previs√£o do modelo\n",
    "                   f_wb = sigmoid(z_wb)\n",
    "    </details>\n",
    "        \n",
    "    </details>\n",
    "    <details>\n",
    "          <summary><font size=\"2\" color=\"darkblue\"><b>Dica para calcular dj_db_i</b></font></summary>\n",
    "           &emsp; &emsp; Voc√™ pode calcular dj_db_i como <code>dj_db_i = f_wb - y[i]</code>\n",
    "    </details>\n",
    "        \n",
    "    <details>\n",
    "          <summary><font size=\"2\" color=\"darkblue\"><b>Dica para calcular dj_dw_ij</b></font></summary>\n",
    "        &emsp; &emsp; Voc√™ pode calcular dj_dw_ij como <code>dj_dw_ij = (f_wb - y[i])* X[i][j]</code>\n",
    "    </details>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute as c√©lulas abaixo para verificar sua implementa√ß√£o da fun√ß√£o `compute_gradient` com duas inicializa√ß√µes diferentes dos par√¢metros $w$ e $b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dj_db com w e b iniciais (zeros):-0.1\n",
      "dj_dw com w e b iniciais (zeros):[-12.00921658929115, -11.262842205513591]\n"
     ]
    }
   ],
   "source": [
    "# Calcular e exibir o gradiente com w e b inicializados como zeros\n",
    "initial_w = np.zeros(n)\n",
    "initial_b = 0.\n",
    "\n",
    "dj_db, dj_dw = compute_gradient(X_train, y_train, initial_w, initial_b)\n",
    "print(f'dj_db com w e b iniciais (zeros):{dj_db}' )\n",
    "print(f'dj_dw com w e b iniciais (zeros):{dj_dw.tolist()}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sa√≠da Esperada**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>dj_db com w e b iniciais (zeros)<b></td>\n",
    "    <td> -0.1 </td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td> <b>dj_dw com w e b iniciais (zeros):<b></td>\n",
    "    <td> [-12.00921658929115, -11.262842205513591] </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dj_db com w e b de teste: -0.5999999999991071\n",
      "dj_dw com w e b de teste: [-44.831353617873795, -44.37384124953978]\n",
      "\u001b[92mAll tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Calcular e exibir o custo e gradiente com w e b n√£o nulos\n",
    "test_w = np.array([ 0.2, -0.5])\n",
    "test_b = -24\n",
    "dj_db, dj_dw  = compute_gradient(X_train, y_train, test_w, test_b)\n",
    "\n",
    "print('dj_db com w e b de teste:', dj_db)\n",
    "print('dj_dw com w e b de teste:', dj_dw.tolist() )\n",
    "\n",
    "# UNIT TESTS    \n",
    "compute_gradient_test(compute_gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sa√≠da Esperada**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>dj_db com w e b de teste:<b></td>\n",
    "    <td> -0.5999999999997627 </td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td> <b>dj_dw com w e b de teste:<b></td>\n",
    "    <td> [ -44.83799720912636, -44.39330400001238] </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2.6\"></a>\n",
    "### 2.6 Aprendendo os par√¢metros usando gradiente descendente\n",
    "\n",
    "Semelhante ao exerc√≠cio anterior, voc√™ agora encontrar√° os par√¢metros √≥timos de um modelo de regress√£o log√≠stica usando gradiente descendente.\n",
    "- Voc√™ n√£o precisa implementar nada para esta parte. Simplesmente execute as c√©lulas abaixo.\n",
    "\n",
    "- Uma boa maneira de verificar se o gradiente descendente est√° funcionando corretamente √© observar o valor de $J(\\mathbf{w},b)$ e verificar se est√° diminuindo a cada passo.\n",
    "\n",
    "- Supondo que voc√™ tenha implementado corretamente o gradiente e calculado o custo, o valor de $J(\\mathbf{w},b)$ nunca deve aumentar e deve convergir para um valor est√°vel at√© o final do algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters, lambda_): \n",
    "    \"\"\"\n",
    "    Realiza o gradiente descendente em lote para aprender theta. Atualiza theta dando \n",
    "    num_iters passos de gradiente com taxa de aprendizado alpha.\n",
    "    \n",
    "    Args:\n",
    "      X :    (ndarray Shape (m, n)) dados, m exemplos por n caracter√≠sticas\n",
    "      y :    (ndarray Shape (m,))  valor alvo \n",
    "      w_in : (ndarray Shape (n,))  Valores iniciais dos par√¢metros do modelo\n",
    "      b_in : (escalar)              Valor inicial do par√¢metro do modelo\n",
    "      cost_function :              fun√ß√£o para calcular o custo\n",
    "      gradient_function :          fun√ß√£o para calcular o gradiente\n",
    "      alpha : (float)              Taxa de aprendizado\n",
    "      num_iters : (int)            n√∫mero de itera√ß√µes para executar o gradiente descendente\n",
    "      lambda_ : (escalar, float)    constante de regulariza√ß√£o\n",
    "      \n",
    "    Retorna:\n",
    "      w : (ndarray Shape (n,)) Valores atualizados dos par√¢metros do modelo ap√≥s\n",
    "          executar o gradiente descendente\n",
    "      b : (escalar)                Valor atualizado do par√¢metro do modelo ap√≥s\n",
    "          executar o gradiente descendente\n",
    "    \"\"\"\n",
    "    \n",
    "    # n√∫mero de exemplos de treinamento\n",
    "    m = len(X)\n",
    "    \n",
    "    # Um array para armazenar o custo J e os valores de w em cada itera√ß√£o, principalmente para gr√°ficos posteriormente\n",
    "    J_history = []\n",
    "    w_history = []\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "\n",
    "        # Calcular o gradiente e atualizar os par√¢metros\n",
    "        dj_db, dj_dw = gradient_function(X, y, w_in, b_in, lambda_)   \n",
    "\n",
    "        # Atualizar os par√¢metros usando w, b, alpha e gradiente\n",
    "        w_in = w_in - alpha * dj_dw               \n",
    "        b_in = b_in - alpha * dj_db              \n",
    "       \n",
    "        # Salvar o custo J em cada itera√ß√£o\n",
    "        if i < 100000:  # prevenir esgotamento de recursos \n",
    "            cost = cost_function(X, y, w_in, b_in, lambda_)\n",
    "            J_history.append(cost)\n",
    "\n",
    "        # Imprimir o custo a cada intervalo de 10 vezes ou tantas itera√ß√µes, se < 10\n",
    "        if i % math.ceil(num_iters / 10) == 0 or i == (num_iters - 1):\n",
    "            w_history.append(w_in)\n",
    "            print(f\"Itera√ß√£o {i:4}: Custo {float(J_history[-1]):8.2f}   \")\n",
    "        \n",
    "    return w_in, b_in, J_history, w_history # retorna w e hist√≥rico de J,w para gr√°ficos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos executar o algoritmo de gradiente descendente acima para aprender os par√¢metros do nosso conjunto de dados.\n",
    "\n",
    "**Nota**\n",
    "O bloco de c√≥digo abaixo leva alguns minutos para ser executado, especialmente com uma vers√£o n√£o vetorizada. Voc√™ pode reduzir as `iterations` para testar sua implementa√ß√£o e iterar mais rapidamente. Se tiver tempo mais tarde, tente executar 100.000 itera√ß√µes para obter melhores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itera√ß√£o    0: Custo     0.96   \n",
      "Itera√ß√£o 1000: Custo     0.31   \n",
      "Itera√ß√£o 2000: Custo     0.30   \n",
      "Itera√ß√£o 3000: Custo     0.30   \n",
      "Itera√ß√£o 4000: Custo     0.30   \n",
      "Itera√ß√£o 5000: Custo     0.30   \n",
      "Itera√ß√£o 6000: Custo     0.30   \n",
      "Itera√ß√£o 7000: Custo     0.30   \n",
      "Itera√ß√£o 8000: Custo     0.30   \n",
      "Itera√ß√£o 9000: Custo     0.30   \n",
      "Itera√ß√£o 9999: Custo     0.30   \n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "initial_w = 0.01 * (np.random.rand(2) - 0.5)\n",
    "initial_b = -8\n",
    "\n",
    "# Algumas configura√ß√µes do gradiente descendente\n",
    "iterations = 10000\n",
    "alpha = 0.001\n",
    "\n",
    "w,b, J_history,_ = gradient_descent(X_train ,y_train, initial_w, initial_b, \n",
    "                                   compute_cost, compute_gradient, alpha, iterations, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <b>Resultado Esperado: Custo     0.30, (Clique para ver detalhes):</b>\n",
    "</summary>\n",
    "\n",
    "    # Com as seguintes configura√ß√µes\n",
    "    np.random.seed(1)\n",
    "    initial_w = 0.01 * (np.random.rand(2) - 0.5)\n",
    "    initial_b = -8\n",
    "    iterations = 10000\n",
    "    alpha = 0.001\n",
    "    #\n",
    "\n",
    "```\n",
    "Itera√ß√£o    0: Custo     0.96   \n",
    "Itera√ß√£o 1000: Custo     0.31   \n",
    "Itera√ß√£o 2000: Custo     0.30   \n",
    "Itera√ß√£o 3000: Custo     0.30   \n",
    "Itera√ß√£o 4000: Custo     0.30   \n",
    "Itera√ß√£o 5000: Custo     0.30   \n",
    "Itera√ß√£o 6000: Custo     0.30   \n",
    "Itera√ß√£o 7000: Custo     0.30   \n",
    "Itera√ß√£o 8000: Custo     0.30   \n",
    "Itera√ß√£o 9000: Custo     0.30   \n",
    "Itera√ß√£o 9999: Custo     0.30   \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2.7\"></a>\n",
    "### 2.7 Plotando a fronteira de decis√£o\n",
    "\n",
    "Agora usaremos os par√¢metros finais do gradiente descendente para plotar o ajuste linear. Se voc√™ implementou as partes anteriores corretamente, dever√° ver um gr√°fico semelhante ao seguinte:\n",
    "<img src=\"images/figure 2.png\"  width=\"450\" height=\"450\">\n",
    "\n",
    "Usaremos uma fun√ß√£o auxiliar no arquivo `utils.py` para criar este gr√°fico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_decision_boundary(w, b, X_train, y_train)\n",
    "# Define o r√≥tulo do eixo y\n",
    "plt.ylabel('Nota do Exame 2') \n",
    "# Define o r√≥tulo do eixo x\n",
    "plt.xlabel('Nota do Exame 1') \n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2.8\"></a>\n",
    "### 2.8 Avaliando a regress√£o log√≠stica\n",
    "\n",
    "Podemos avaliar a qualidade dos par√¢metros que encontramos verificando o qu√£o bem o modelo aprendido prev√™ em nosso conjunto de treinamento.\n",
    "\n",
    "Voc√™ implementar√° a fun√ß√£o `predict` abaixo para fazer isso.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-04'></a>\n",
    "### Exerc√≠cio 4\n",
    "\n",
    "Por favor, complete a fun√ß√£o `predict` para produzir previs√µes de `1` ou `0` dado um conjunto de dados e um vetor de par√¢metros aprendidos $w$ e $b$.\n",
    "- Primeiro, voc√™ precisa calcular a previs√£o do modelo $f(x^{(i)}) = g(w \\cdot x^{(i)} + b)$ para cada exemplo\n",
    "    - Voc√™ j√° implementou isso nas partes acima\n",
    "- Interpretamos a sa√≠da do modelo ($f(x^{(i)})$) como a probabilidade de que $y^{(i)}=1$ dado $x^{(i)}$ e parametrizado por $w$.\n",
    "- Portanto, para obter uma previs√£o final ($y^{(i)}=0$ ou $y^{(i)}=1$) do modelo de regress√£o log√≠stica, voc√™ pode usar a seguinte heur√≠stica:\n",
    "\n",
    "  se $f(x^{(i)}) >= 0.5$, prever $y^{(i)}=1$\n",
    "  \n",
    "  se $f(x^{(i)}) < 0.5$, prever $y^{(i)}=0$\n",
    "    \n",
    "Se voc√™ ficar preso, pode conferir as dicas apresentadas ap√≥s a c√©lula abaixo para ajud√°-lo na implementa√ß√£o.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C4\n",
    "# GRADED FUNCTION: predict\n",
    "\n",
    "def predict(X, w, b): \n",
    "    \"\"\"\n",
    "    Prever se o r√≥tulo √© 0 ou 1 usando os par√¢metros de regress√£o log√≠stica aprendidos w\n",
    "    \n",
    "    Args:\n",
    "      X : (ndarray Shape (m,n)) dados, m exemplos por n caracter√≠sticas\n",
    "      w : (ndarray Shape (n,))  valores dos par√¢metros do modelo      \n",
    "      b : (scalar)              valor do par√¢metro de vi√©s do modelo\n",
    "\n",
    "    Returns:\n",
    "      p : (ndarray (m,)) As previs√µes para X usando um limiar de 0,5\n",
    "    \"\"\"\n",
    "    # n√∫mero de exemplos de treinamento\n",
    "    m, n = X.shape   \n",
    "    p = np.zeros(m)\n",
    "   \n",
    "    f_wb= 0\n",
    "    ### IN√çCIO DO C√ìDIGO ### \n",
    "    # Loop sobre cada exemplo\n",
    "    for i in range(m):   \n",
    "        z_wb = 0\n",
    "        # Loop sobre cada caracter√≠stica\n",
    "        for j in range(n):\n",
    "            # Adicione o termo correspondente a z_wb\n",
    "            z_wb_ij = X[i, j] * w[j]\n",
    "            z_wb += z_wb_ij\n",
    "        \n",
    "        # Adiciona o termo de vi√©s \n",
    "        z_wb += b\n",
    "        \n",
    "        # Calcula a previs√£o para este exemplo\n",
    "        f_wb = sigmoid(z_wb)\n",
    "\n",
    "        # Aplica o limiar\n",
    "        p[i] = f_wb >= 0.5\n",
    "        \n",
    "    ### FIM DO C√ìDIGO ### \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><font size=\"3\" color=\"darkgreen\"><b>Clique para ver dicas</b></font></summary>\n",
    "    \n",
    "* Aqui est√° como voc√™ pode estruturar a implementa√ß√£o geral para esta fun√ß√£o:\n",
    "    ```python \n",
    "       def predict(X, w, b): \n",
    "            # n√∫mero de exemplos de treinamento\n",
    "            m, n = X.shape   \n",
    "            p = np.zeros(m)\n",
    "   \n",
    "            ### IN√çCIO DO C√ìDIGO ### \n",
    "            # Loop sobre cada exemplo\n",
    "            for i in range(m):   \n",
    "                \n",
    "                # Calcule f_wb (exatamente como voc√™ fez na fun√ß√£o compute_cost acima) \n",
    "                # usando algumas linhas de c√≥digo\n",
    "                f_wb = \n",
    "\n",
    "                # Calcule a previs√£o para esse exemplo de treinamento \n",
    "                p[i] = # Seu c√≥digo aqui para calcular a previs√£o com base em f_wb\n",
    "        \n",
    "            ### FIM DO C√ìDIGO ### \n",
    "            return p\n",
    "    ```\n",
    "  \n",
    "    Se voc√™ ainda estiver com dificuldades, voc√™ pode verificar as dicas apresentadas abaixo para descobrir como calcular `f_wb` e `p[i]`.\n",
    "    \n",
    "    <details>\n",
    "          <summary><font size=\"2\" color=\"darkblue\"><b>Dica para calcular f_wb</b></font></summary>\n",
    "           &emsp; &emsp; Lembre-se de que voc√™ calculou f_wb na fun√ß√£o <code>compute_cost</code> acima ‚Äî para dicas detalhadas sobre como calcular cada termo intermedi√°rio, confira a se√ß√£o de dicas abaixo desse exerc√≠cio.\n",
    "           <details>\n",
    "              <summary><font size=\"2\" color=\"blue\"><b>&emsp; &emsp; Mais dicas para calcular f_wb</b></font></summary>\n",
    "              &emsp; &emsp; Voc√™ pode calcular f_wb como\n",
    "               <pre>\n",
    "               for i in range(m):   \n",
    "                   # Calcule f_wb (exatamente como voc√™ fez na fun√ß√£o compute_cost acima)\n",
    "                   z_wb = 0\n",
    "                   # Loop sobre cada caracter√≠stica\n",
    "                   for j in range(n): \n",
    "                       # Adicione o termo correspondente a z_wb\n",
    "                       z_wb_ij = X[i, j] * w[j]\n",
    "                       z_wb += z_wb_ij\n",
    "            \n",
    "                   # Adicione o termo de vi√©s \n",
    "                   z_wb += b\n",
    "        \n",
    "                   # Calcule a previs√£o do modelo\n",
    "                   f_wb = sigmoid(z_wb)\n",
    "    </details>\n",
    "        \n",
    "    </details>\n",
    "    <details>\n",
    "          <summary><font size=\"2\" color=\"darkblue\"><b>Dica para calcular p[i]</b></font></summary>\n",
    "           &emsp; &emsp; Por exemplo, se voc√™ quiser definir x = 1 se y for menor que 3 e 0 caso contr√°rio, voc√™ pode expressar isso em c√≥digo como <code>x = y < 3</code>. Agora fa√ßa o mesmo para p[i] = 1 se f_wb >= 0.5 e 0 caso contr√°rio.\n",
    "           <details>\n",
    "              <summary><font size=\"2\" color=\"blue\"><b>&emsp; &emsp; Mais dicas para calcular p[i]</b></font></summary>\n",
    "              &emsp; &emsp; Voc√™ pode calcular p[i] como <code>p[i] = f_wb >= 0.5</code>\n",
    "          </details>\n",
    "    </details>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois de completar a fun√ß√£o `predict`, execute o c√≥digo abaixo para relatar a acur√°cia de treinamento do seu classificador, calculando a porcentagem de exemplos que ele acertou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sa√≠da da previs√£o: formato (4,), valor [0. 1. 1. 1.]\n",
      "\u001b[92mAll tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Teste seu c√≥digo de previs√£o\n",
    "np.random.seed(1)\n",
    "tmp_w = np.random.randn(2)\n",
    "tmp_b = 0.3    \n",
    "tmp_X = np.random.randn(4, 2) - 0.5\n",
    "\n",
    "tmp_p = predict(tmp_X, tmp_w, tmp_b)\n",
    "print(f'Sa√≠da da previs√£o: formato {tmp_p.shape}, valor {tmp_p}')\n",
    "\n",
    "# UNIT TESTS        \n",
    "predict_test(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sa√≠da esperada**\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>Sa√≠da da previs√£o: formato (4,), valor [0. 1. 1. 1.]<b></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos usar isso para calcular a precis√£o no conjunto de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precis√£o no Treinamento: 92.000000\n"
     ]
    }
   ],
   "source": [
    "# Calcular a precis√£o no nosso conjunto de treinamento\n",
    "p = predict(X_train, w, b)\n",
    "print('Precis√£o no Treinamento: %f' % (np.mean(p == y_train) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>Precis√£o no Treinamento (aproximadamente):<b></td>\n",
    "    <td> 92.00 </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a>\n",
    "## 3 - Regress√£o Log√≠stica Regularizada\n",
    "\n",
    "Nesta parte do exerc√≠cio, voc√™ implementar√° a regress√£o log√≠stica regularizada para prever se microchips de uma f√°brica passam pela garantia de qualidade (QA). Durante a QA, cada microchip passa por v√°rios testes para garantir que est√° funcionando corretamente.\n",
    "\n",
    "<a name=\"3.1\"></a>\n",
    "### 3.1 Declara√ß√£o do Problema\n",
    "\n",
    "Suponha que voc√™ seja o gerente de produto da f√°brica e tenha os resultados dos testes para alguns microchips em dois testes diferentes.\n",
    "- A partir desses dois testes, voc√™ gostaria de determinar se os microchips devem ser aceitos ou rejeitados.\n",
    "- Para ajudar voc√™ a tomar a decis√£o, voc√™ tem um conjunto de dados com os resultados de testes de microchips anteriores, com o qual voc√™ pode construir um modelo de regress√£o log√≠stica.\n",
    "\n",
    "<a name=\"3.2\"></a>\n",
    "### 3.2 Carregando e visualizando os dados\n",
    "\n",
    "Semelhante √†s partes anteriores deste exerc√≠cio, vamos come√ßar carregando o conjunto de dados para esta tarefa e visualizando-o.\n",
    "\n",
    "- A fun√ß√£o `load_dataset()` mostrada abaixo carrega os dados nas vari√°veis `X_train` e `y_train`\n",
    "  - `X_train` cont√©m os resultados dos testes dos microchips em dois testes\n",
    "  - `y_train` cont√©m os resultados da QA  \n",
    "      - `y_train = 1` se o microchip foi aceito \n",
    "      - `y_train = 0` se o microchip foi rejeitado \n",
    "  - Tanto `X_train` quanto `y_train` s√£o arrays numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# carregar conjunto de dados\n",
    "X_train, y_train = load_data(\"data/ex2data2.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize as vari√°veis\n",
    "\n",
    "O c√≥digo abaixo imprime os primeiros cinco valores de `X_train` e `y_train` e o tipo das vari√°veis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: [[ 0.051267  0.69956 ]\n",
      " [-0.092742  0.68494 ]\n",
      " [-0.21371   0.69225 ]\n",
      " [-0.375     0.50219 ]\n",
      " [-0.51325   0.46564 ]]\n",
      "Tipo de X_train: <class 'numpy.ndarray'>\n",
      "y_train: [1. 1. 1. 1. 1.]\n",
      "Tipo de y_train: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# imprimir X_train\n",
    "print(\"X_train:\", X_train[:5])\n",
    "print(\"Tipo de X_train:\", type(X_train))\n",
    "\n",
    "# imprimir y_train\n",
    "print(\"y_train:\", y_train[:5])\n",
    "print(\"Tipo de y_train:\", type(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verifique as dimens√µes das suas vari√°veis\n",
    "\n",
    "Outra maneira √∫til de se familiarizar com seus dados √© visualizar suas dimens√µes. Vamos imprimir a forma de `X_train` e `y_train` e ver quantos exemplos de treinamento temos em nosso conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A forma de X_train √©: (118, 2)\n",
      "A forma de y_train √©: (118,)\n",
      "Temos m = 118 exemplos de treinamento\n"
     ]
    }
   ],
   "source": [
    "print('A forma de X_train √©: ' + str(X_train.shape))\n",
    "print('A forma de y_train √©: ' + str(y_train.shape))\n",
    "print('Temos m = %d exemplos de treinamento' % (len(y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize seus dados\n",
    "\n",
    "A fun√ß√£o auxiliar `plot_data` (de `utils.py`) √© usada para gerar uma figura como a Figura 3, onde os eixos s√£o os dois resultados dos testes, e os exemplos positivos (y = 1, aceito) e negativos (y = 0, rejeitado) s√£o mostrados com marcadores diferentes.\n",
    "\n",
    "<img src=\"images/figure 3.png\" width=\"450\" height=\"450\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotar exemplos\n",
    "plot_data(X_train, y_train[:], pos_label=\"Aceito\", neg_label=\"Rejeitado\")\n",
    "\n",
    "# Definir o r√≥tulo do eixo y\n",
    "plt.ylabel('Teste de Microchip 2') \n",
    "# Definir o r√≥tulo do eixo x\n",
    "plt.xlabel('Teste de Microchip 1') \n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Figura 3 mostra que nosso conjunto de dados n√£o pode ser separado em exemplos positivos e negativos por uma linha reta atrav√©s do gr√°fico. Portanto, uma aplica√ß√£o direta da regress√£o log√≠stica n√£o funcionar√° bem neste conjunto de dados, j√° que a regress√£o log√≠stica s√≥ poder√° encontrar um limite de decis√£o linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Mapeamento de Caracter√≠sticas\n",
    "\n",
    "Uma maneira de ajustar melhor os dados √© criar mais caracter√≠sticas a partir de cada ponto de dados. Na fun√ß√£o fornecida `map_feature`, mapeamos as caracter√≠sticas em todos os termos polinomiais de $x_1$ e $x_2$ at√© a sexta pot√™ncia.\n",
    "\n",
    "$$\\mathrm{map\\_feature}(x) = \n",
    "\\left[\\begin{array}{c}\n",
    "x_1\\\\\n",
    "x_2\\\\\n",
    "x_1^2\\\\\n",
    "x_1 x_2\\\\\n",
    "x_2^2\\\\\n",
    "x_1^3\\\\\n",
    "\\vdots\\\\\n",
    "x_1 x_2^5\\\\\n",
    "x_2^6\\end{array}\\right]$$\n",
    "\n",
    "\n",
    "Como resultado desse mapeamento, nosso vetor de duas caracter√≠sticas (os resultados em dois testes de QA) foi transformado em um vetor de 27 dimens√µes.\n",
    "\n",
    "- Um classificador de regress√£o log√≠stica treinado nesse vetor de caracter√≠sticas de maior dimens√£o ter√° um limite de decis√£o mais complexo e ser√° n√£o linear quando desenhado em nosso gr√°fico 2-dimensional.\n",
    "- A fun√ß√£o `map_feature` foi fornecida para voc√™ em `utils.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma original dos dados: (118, 2)\n",
      "Forma ap√≥s o mapeamento de caracter√≠sticas: (118, 27)\n"
     ]
    }
   ],
   "source": [
    "print(\"Forma original dos dados:\", X_train.shape)\n",
    "\n",
    "mapped_X = map_feature(X_train[:, 0], X_train[:, 1])\n",
    "print(\"Forma ap√≥s o mapeamento de caracter√≠sticas:\", mapped_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos tamb√©m imprimir os primeiros elementos de `X_train` e `mapped_X` para ver a transforma√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train[0]: [0.051267 0.69956 ]\n",
      "mapped X_train[0]: [5.12670000e-02 6.99560000e-01 2.62830529e-03 3.58643425e-02\n",
      " 4.89384194e-01 1.34745327e-04 1.83865725e-03 2.50892595e-02\n",
      " 3.42353606e-01 6.90798869e-06 9.42624411e-05 1.28625106e-03\n",
      " 1.75514423e-02 2.39496889e-01 3.54151856e-07 4.83255257e-06\n",
      " 6.59422333e-05 8.99809795e-04 1.22782870e-02 1.67542444e-01\n",
      " 1.81563032e-08 2.47750473e-07 3.38066048e-06 4.61305487e-05\n",
      " 6.29470940e-04 8.58939846e-03 1.17205992e-01]\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train[0]:\", X_train[0])\n",
    "print(\"mapped X_train[0]:\", mapped_X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embora o mapeamento de caracter√≠sticas nos permita construir um classificador mais expressivo, ele tamb√©m √© mais suscet√≠vel ao sobreajuste. Nas pr√≥ximas partes do exerc√≠cio, voc√™ implementar√° a regress√£o log√≠stica regularizada para ajustar os dados e tamb√©m ver√° como a regulariza√ß√£o pode ajudar a combater o problema do sobreajuste.\n",
    "\n",
    "<a name=\"3.4\"></a>\n",
    "### 3.4 Fun√ß√£o de Custo para Regress√£o Log√≠stica Regularizada\n",
    "\n",
    "Nesta parte, voc√™ implementar√° a fun√ß√£o de custo para a regress√£o log√≠stica regularizada.\n",
    "\n",
    "Lembre-se de que, para a regress√£o log√≠stica regularizada, a fun√ß√£o de custo √© da forma\n",
    "$$J(\\mathbf{w},b) = \\frac{1}{m} \\sum_{i=0}^{m-1} \\left[ -y^{(i)} \\log\\left(f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) - \\left( 1 - y^{(i)}\\right) \\log \\left( 1 - f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) \\right] + \\frac{\\lambda}{2m} \\sum_{j=0}^{n-1} w_j^2$$\n",
    "\n",
    "Compare isso com a fun√ß√£o de custo sem regulariza√ß√£o (que voc√™ implementou acima), que √© da forma \n",
    "\n",
    "$$ J(\\mathbf{w},b) = \\frac{1}{m}\\sum_{i=0}^{m-1} \\left[ -y^{(i)} \\log\\left(f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) - \\left( 1 - y^{(i)}\\right) \\log \\left( 1 - f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) \\right]$$\n",
    "\n",
    "A diferen√ßa √© o termo de regulariza√ß√£o, que √© $$\\frac{\\lambda}{2m} \\sum_{j=0}^{n-1} w_j^2$$ \n",
    "Observe que o par√¢metro $b$ n√£o √© regularizado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-05'></a>\n",
    "### Exerc√≠cio 5\n",
    "\n",
    "Por favor, complete a fun√ß√£o `compute_cost_reg` abaixo para calcular o seguinte termo para cada elemento em $w$\n",
    "$$\\frac{\\lambda}{2m} \\sum_{j=0}^{n-1} w_j^2$$\n",
    "\n",
    "O c√≥digo inicial ent√£o adiciona isso ao custo sem regulariza√ß√£o (que voc√™ calculou acima em `compute_cost`) para calcular o custo com regulariza√ß√£o.\n",
    "\n",
    "Se voc√™ ficar preso, pode conferir as dicas apresentadas ap√≥s a c√©lula abaixo para ajud√°-lo com a implementa√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C5\n",
    "def compute_cost_reg(X, y, w, b, lambda_ = 1):\n",
    "    \"\"\"\n",
    "    Calcula o custo sobre todos os exemplos\n",
    "    Args:\n",
    "      X : (ndarray Shape (m,n)) dados, m exemplos por n caracter√≠sticas\n",
    "      y : (ndarray Shape (m,)) valor alvo \n",
    "      w : (ndarray Shape (n,)) valores dos par√¢metros do modelo      \n",
    "      b : (escalar) valor do par√¢metro de vi√©s do modelo\n",
    "      lambda_ : (escala, float) Controla a quantidade de regulariza√ß√£o\n",
    "    Returns:\n",
    "      total_cost : (escala) custo \n",
    "    \"\"\"\n",
    "\n",
    "    m, n = X.shape\n",
    "    \n",
    "    # Chama a fun√ß√£o compute_cost que voc√™ implementou acima\n",
    "    cost_without_reg = compute_cost(X, y, w, b) \n",
    "    \n",
    "    # Voc√™ precisa calcular esse valor\n",
    "    reg_cost = 0.\n",
    "    \n",
    "    ### IN√çCIO DO C√ìDIGO AQUI ###\n",
    "    for j in range(n):\n",
    "        reg_cost_j = w[j]**2\n",
    "        reg_cost = reg_cost + reg_cost_j\n",
    "    reg_cost = (lambda_/(2 * m)) * reg_cost\n",
    "        \n",
    "    ### FIM DO C√ìDIGO AQUI ### \n",
    "    \n",
    "    # Adiciona o custo de regulariza√ß√£o para obter o custo total\n",
    "    total_cost = cost_without_reg + reg_cost\n",
    "\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><font size=\"3\" color=\"darkgreen\"><b>Clique para dicas</b></font></summary>\n",
    "    \n",
    "    \n",
    "* Aqui est√° como voc√™ pode estruturar a implementa√ß√£o geral para esta fun√ß√£o\n",
    "    \n",
    "    ```python\n",
    "    def compute_cost_reg(X, y, w, b, lambda_ = 1):\n",
    "   \n",
    "        m, n = X.shape\n",
    "\n",
    "        # Chama a fun√ß√£o compute_cost que voc√™ implementou acima\n",
    "        cost_without_reg = compute_cost(X, y, w, b) \n",
    "\n",
    "        # Voc√™ precisa calcular esse valor\n",
    "        reg_cost = 0.\n",
    "\n",
    "        ### IN√çCIO DO C√ìDIGO AQUI ###\n",
    "        for j in range(n):\n",
    "            reg_cost_j = # Seu c√≥digo aqui para calcular o custo de w[j]\n",
    "            reg_cost = reg_cost + reg_cost_j\n",
    "        reg_cost = (lambda_/(2 * m)) * reg_cost\n",
    "        ### FIM DO C√ìDIGO AQUI ### \n",
    "\n",
    "        # Adiciona o custo de regulariza√ß√£o para obter o custo total\n",
    "        total_cost = cost_without_reg + reg_cost\n",
    "\n",
    "    return total_cost\n",
    "    ```\n",
    "  \n",
    "    Se voc√™ ainda estiver preso, pode conferir as dicas apresentadas abaixo para descobrir como calcular `reg_cost_j` \n",
    "    \n",
    "    <details>\n",
    "        <summary><font size=\"2\" color=\"darkblue\"><b>Dica para calcular reg_cost_j</b></font></summary>\n",
    "        &emsp; &emsp; Voc√™ pode calcular reg_cost_j como <code>reg_cost_j = w[j]**2 </code> \n",
    "    </details>\n",
    "        \n",
    "    </details>\n",
    "\n",
    "</details>\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute a c√©lula abaixo para verificar sua implementa√ß√£o da fun√ß√£o `compute_cost_reg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custo regularizado : 0.6618252552483948\n",
      "\u001b[92mAll tests passed!\n"
     ]
    }
   ],
   "source": [
    "X_mapped = map_feature(X_train[:, 0], X_train[:, 1])\n",
    "np.random.seed(1)\n",
    "initial_w = np.random.rand(X_mapped.shape[1]) - 0.5\n",
    "initial_b = 0.5\n",
    "lambda_ = 0.5\n",
    "cost = compute_cost_reg(X_mapped, y_train, initial_w, initial_b, lambda_)\n",
    "\n",
    "print(\"Custo regularizado :\", cost)\n",
    "\n",
    "# UNIT TEST    \n",
    "compute_cost_reg_test(compute_cost_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sa√≠da Esperada**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>Custo regularizado : <b></td>\n",
    "    <td> 0.6618252552483948 </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3.5\"></a>\n",
    "### 3.5 Gradiente para Regress√£o Log√≠stica Regularizada\n",
    "\n",
    "Nesta se√ß√£o, voc√™ implementar√° o gradiente para a regress√£o log√≠stica regularizada.\n",
    "\n",
    "O gradiente da fun√ß√£o de custo regularizada possui dois componentes. O primeiro, $\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}$, √© um escalar; o outro √© um vetor com a mesma forma dos par√¢metros $\\mathbf{w}$, onde o $j^\\mathrm{th}$ elemento √© definido como segue:\n",
    "\n",
    "$$\\frac{\\partial J(\\mathbf{w},b)}{\\partial b} = \\frac{1}{m}  \\sum_{i=0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})  $$\n",
    "\n",
    "$$\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j} = \\left( \\frac{1}{m}  \\sum_{i=0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)}) x_j^{(i)} \\right) + \\frac{\\lambda}{m} w_j  \\quad\\, \\mbox{para $j=0...(n-1)$}$$\n",
    "\n",
    "Compare isto com o gradiente da fun√ß√£o de custo sem regulariza√ß√£o (que voc√™ implementou acima), que √© da forma:\n",
    "$$\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  = \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - \\mathbf{y}^{(i)}) \\tag{2}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  = \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - \\mathbf{y}^{(i)})x_{j}^{(i)} \\tag{3}\n",
    "$$\n",
    "\n",
    "Como voc√™ pode ver, $\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}$ √© o mesmo; a diferen√ßa est√° no seguinte termo em $\\frac{\\partial J(\\mathbf{w},b)}{\\partial w}$, que √© $$\\frac{\\lambda}{m} w_j  \\quad\\, \\mbox{para $j=0...(n-1)$}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-06'></a>\n",
    "### Exerc√≠cio 6\n",
    "\n",
    "Por favor, complete a fun√ß√£o `compute_gradient_reg` abaixo para modificar o c√≥digo a seguir e calcular o seguinte termo:\n",
    "\n",
    "$$\\frac{\\lambda}{m} w_j  \\quad\\, \\mbox{para $j=0...(n-1)$}$$\n",
    "\n",
    "O c√≥digo inicial adicionar√° esse termo ao $\\frac{\\partial J(\\mathbf{w},b)}{\\partial w}$ retornado pela fun√ß√£o `compute_gradient` acima para obter o gradiente para a fun√ß√£o de custo regularizada.\n",
    "\n",
    "Se voc√™ ficar preso, pode verificar as dicas apresentadas ap√≥s a c√©lula abaixo para ajudar na implementa√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C6\n",
    "def compute_gradient_reg(X, y, w, b, lambda_ = 1): \n",
    "    \"\"\"\n",
    "    Calcula o gradiente para a regress√£o log√≠stica com regulariza√ß√£o\n",
    "\n",
    "    Args:\n",
    "      X : (ndarray Shape (m,n)) dados, m exemplos por n caracter√≠sticas\n",
    "      y : (ndarray Shape (m,)) valor alvo \n",
    "      w : (ndarray Shape (n,)) valores dos par√¢metros do modelo      \n",
    "      b : (escalar) valor do par√¢metro de vi√©s do modelo\n",
    "      lambda_ : (escalar, float) constante de regulariza√ß√£o\n",
    "    Returns\n",
    "      dj_db : (escalar) O gradiente do custo em rela√ß√£o ao par√¢metro b. \n",
    "      dj_dw : (ndarray Shape (n,)) O gradiente do custo em rela√ß√£o aos par√¢metros w. \n",
    "\n",
    "    \"\"\"\n",
    "    m, n = X.shape\n",
    "    \n",
    "    dj_db, dj_dw = compute_gradient(X, y, w, b)\n",
    "\n",
    "    ### COME√áO DO C√ìDIGO AQUI ###     \n",
    "    for j in range(n): \n",
    "\n",
    "        dj_dw_j_reg = (lambda_ / m) * w[j]\n",
    "\n",
    "        # Adicione o termo de regulariza√ß√£o ao elemento correspondente de dj_dw\n",
    "        dj_dw[j] = dj_dw[j] + dj_dw_j_reg\n",
    "\n",
    "    ### FIM DO C√ìDIGO AQUI ###         \n",
    "    \n",
    "    return dj_db, dj_dw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><font size=\"3\" color=\"darkgreen\"><b>Clique para dicas</b></font></summary>\n",
    "  \n",
    "* Aqui est√° como voc√™ pode estruturar a implementa√ß√£o geral para esta fun√ß√£o\n",
    "\n",
    "  ```python\n",
    "      def compute_gradient_reg(X, y, w, b, lambda_ = 1): \n",
    "          m, n = X.shape\n",
    "      \n",
    "          dj_db, dj_dw = compute_gradient(X, y, w, b)\n",
    "\n",
    "          ### COME√áO DO C√ìDIGO AQUI ###     \n",
    "          # Percorra os elementos de w\n",
    "          for j in range(n): \n",
    "              \n",
    "              dj_dw_j_reg = # Seu c√≥digo aqui para calcular o termo de regulariza√ß√£o para dj_dw[j]\n",
    "              \n",
    "              # Adicione o termo de regulariza√ß√£o ao elemento correspondente de dj_dw\n",
    "              dj_dw[j] = dj_dw[j] + dj_dw_j_reg\n",
    "          \n",
    "          ### FIM DO C√ìDIGO AQUI ###         \n",
    "          \n",
    "          return dj_db, dj_dw\n",
    "  ```\n",
    "\n",
    "    Se voc√™ ainda estiver com dificuldades, pode conferir as dicas apresentadas abaixo para descobrir como calcular `dj_dw_j_reg`\n",
    "    \n",
    "    <details>\n",
    "          <summary><font size=\"2\" color=\"darkblue\"><b>Dica para calcular dj_dw_j_reg</b></font></summary>\n",
    "           &emsp; &emsp; Voc√™ pode calcular `dj_dw_j_reg` como <code>dj_dw_j_reg = (lambda_ / m) * w[j] </code> \n",
    "    </details>\n",
    "        \n",
    "    </details>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute a c√©lula abaixo para verificar sua implementa√ß√£o da fun√ß√£o `compute_gradient_reg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dj_db: 0.07138288792343662\n",
      "Primeiros elementos de dj_dw regularizado:\n",
      " [-0.010386028450548701, 0.011409852883280124, 0.0536273463274574, 0.003140278267313462]\n",
      "\u001b[92mAll tests passed!\n"
     ]
    }
   ],
   "source": [
    "X_mapped = map_feature(X_train[:, 0], X_train[:, 1])\n",
    "np.random.seed(1) \n",
    "initial_w  = np.random.rand(X_mapped.shape[1]) - 0.5 \n",
    "initial_b = 0.5\n",
    " \n",
    "lambda_ = 0.5\n",
    "dj_db, dj_dw = compute_gradient_reg(X_mapped, y_train, initial_w, initial_b, lambda_)\n",
    "\n",
    "print(f\"dj_db: {dj_db}\", )\n",
    "print(f\"Primeiros elementos de dj_dw regularizado:\\n {dj_dw[:4].tolist()}\", )\n",
    "\n",
    "# UNIT TESTS    \n",
    "compute_gradient_reg_test(compute_gradient_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sa√≠da Esperada**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>dj_db:</b>0.07138288792343</td> </tr>\n",
    "  <tr>\n",
    "      <td> <b> Primeiros elementos de dj_dw regularizado:</b> </td> </tr>\n",
    "   <tr>\n",
    "   <td> [[-0.010386028450548], [0.011409852883280], [0.0536273463274], [0.003140278267313]] </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3.6\"></a>\n",
    "### 3.6 Aprendendo os par√¢metros usando gradiente descendente\n",
    "\n",
    "Semelhante √†s partes anteriores, voc√™ usar√° sua fun√ß√£o de gradiente descendente implementada acima para aprender os par√¢metros √≥timos $w$, $b$.\n",
    "- Se voc√™ completou corretamente o custo e o gradiente para a regress√£o log√≠stica regularizada, voc√™ deve ser capaz de seguir a pr√≥xima c√©lula para aprender os par√¢metros $w$.\n",
    "- Ap√≥s treinar nossos par√¢metros, usaremos isso para plotar a fronteira de decis√£o.\n",
    "\n",
    "**Nota**\n",
    "\n",
    "O bloco de c√≥digo abaixo leva um tempo consider√°vel para rodar, especialmente com uma vers√£o n√£o vetorizada. Voc√™ pode reduzir as itera√ß√µes para testar sua implementa√ß√£o e iterar mais rapidamente. Se tiver tempo depois, execute por 100.000 itera√ß√µes para ver melhores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itera√ß√£o    0: Custo     0.72   \n",
      "Itera√ß√£o 1000: Custo     0.59   \n",
      "Itera√ß√£o 2000: Custo     0.56   \n",
      "Itera√ß√£o 3000: Custo     0.53   \n",
      "Itera√ß√£o 4000: Custo     0.51   \n",
      "Itera√ß√£o 5000: Custo     0.50   \n",
      "Itera√ß√£o 6000: Custo     0.48   \n",
      "Itera√ß√£o 7000: Custo     0.47   \n",
      "Itera√ß√£o 8000: Custo     0.46   \n",
      "Itera√ß√£o 9000: Custo     0.45   \n",
      "Itera√ß√£o 9999: Custo     0.45   \n"
     ]
    }
   ],
   "source": [
    "# Inicialize os par√¢metros de ajuste\n",
    "np.random.seed(1)\n",
    "initial_w = np.random.rand(X_mapped.shape[1])-0.5\n",
    "initial_b = 1.\n",
    "\n",
    "# Defina o par√¢metro de regulariza√ß√£o lambda_ (voc√™ pode tentar variar isso)\n",
    "lambda_ = 0.01    \n",
    "\n",
    "# Algumas configura√ß√µes de gradiente descendente\n",
    "iterations = 10000\n",
    "alpha = 0.01\n",
    "\n",
    "w,b, J_history,_ = gradient_descent(X_mapped, y_train, initial_w, initial_b, \n",
    "                                    compute_cost_reg, compute_gradient_reg, \n",
    "                                    alpha, iterations, lambda_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <b>Sa√≠da Esperada: Custo < 0.5  (Clique para detalhes)</b>\n",
    "</summary>\n",
    "\n",
    "# Usando as seguintes configura√ß√µes\n",
    "#np.random.seed(1)\n",
    "#initial_w = np.random.rand(X_mapped.shape[1])-0.5\n",
    "#initial_b = 1.\n",
    "#lambda_ = 0.01;                                          \n",
    "#iterations = 10000\n",
    "#alpha = 0.01\n",
    "Itera√ß√£o    0: Custo     0.72   \n",
    "Itera√ß√£o 1000: Custo     0.59   \n",
    "Itera√ß√£o 2000: Custo     0.56   \n",
    "Itera√ß√£o 3000: Custo     0.53   \n",
    "Itera√ß√£o 4000: Custo     0.51   \n",
    "Itera√ß√£o 5000: Custo     0.50   \n",
    "Itera√ß√£o 6000: Custo     0.48   \n",
    "Itera√ß√£o 7000: Custo     0.47   \n",
    "Itera√ß√£o 8000: Custo     0.46   \n",
    "Itera√ß√£o 9000: Custo     0.45   \n",
    "Itera√ß√£o 9999: Custo     0.45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3.7\"></a>\n",
    "### 3.7 Plotando a Fronteira de Decis√£o\n",
    "\n",
    "Para ajud√°-lo a visualizar o modelo aprendido por este classificador, usaremos nossa fun√ß√£o `plot_decision_boundary` que plota a fronteira de decis√£o (n√£o linear) que separa os exemplos positivos e negativos.\n",
    "\n",
    "- Na fun√ß√£o, plotamos a fronteira de decis√£o n√£o linear calculando as previs√µes do classificador em uma grade espa√ßada uniformemente e, em seguida, desenhamos um gr√°fico de contorno onde as previs√µes mudam de y = 0 para y = 1.\n",
    "\n",
    "- Ap√≥s aprender os par√¢metros $w$, $b$, o pr√≥ximo passo √© plotar uma fronteira de decis√£o semelhante √† Figura 4.\n",
    "\n",
    "<img src=\"images/figure 4.png\"  width=\"450\" height=\"450\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_decision_boundary(w, b, X_mapped, y_train)\n",
    "# Defina o r√≥tulo do eixo y\n",
    "plt.ylabel('Teste de Microchip 2') \n",
    "# Defina o r√≥tulo do eixo x\n",
    "plt.xlabel('Teste de Microchip 1') \n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3.8\"></a>\n",
    "### 3.8 Avaliando o Modelo de Regress√£o Log√≠stica Regularizada\n",
    "\n",
    "Voc√™ usar√° a fun√ß√£o `predict` que voc√™ implementou acima para calcular a precis√£o do modelo de regress√£o log√≠stica regularizada no conjunto de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precis√£o de Treinamento: 82.203390\n"
     ]
    }
   ],
   "source": [
    "# Calcule a precis√£o no conjunto de treinamento\n",
    "p = predict(X_mapped, w, b)\n",
    "\n",
    "print('Precis√£o de Treinamento: %f'%(np.mean(p == y_train) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>Train Accuracy:</b>~ 80%</td> </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations on completing the final lab of this course! We hope to see you in Course 2 where you will use more advanced learning algorithms such as neural networks and decision trees. Keep learning!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><font size=\"2\" color=\"darkgreen\"><b>Please click here if you want to experiment with any of the non-graded code.</b></font></summary>\n",
    "    <p><i><b>Important Note: Please only do this when you've already passed the assignment to avoid problems with the autograder.</b></i>\n",
    "    <ol>\n",
    "        <li> On the notebook‚Äôs menu, click ‚ÄúView‚Äù > ‚ÄúCell Toolbar‚Äù > ‚ÄúEdit Metadata‚Äù</li>\n",
    "        <li> Hit the ‚ÄúEdit Metadata‚Äù button next to the code cell which you want to lock/unlock</li>\n",
    "        <li> Set the attribute value for ‚Äúeditable‚Äù to:\n",
    "            <ul>\n",
    "                <li> ‚Äútrue‚Äù if you want to unlock it </li>\n",
    "                <li> ‚Äúfalse‚Äù if you want to lock it </li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li> On the notebook‚Äôs menu, click ‚ÄúView‚Äù > ‚ÄúCell Toolbar‚Äù > ‚ÄúNone‚Äù </li>\n",
    "    </ol>\n",
    "    <p> Here's a short demo of how to do the steps above: \n",
    "        <br>\n",
    "        <img src=\"https://lh3.google.com/u/0/d/14Xy_Mb17CZVgzVAgq7NCjMVBvSae3xO1\" align=\"center\" alt=\"unlock_cells.gif\">\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
